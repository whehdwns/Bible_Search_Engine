{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da18cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dongj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dongj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import time\n",
    "import operator\n",
    "from itertools import islice\n",
    "\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e63f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d619ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_content_w_ch =[]\n",
    "with open('kjv.txt') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        book_content_w_ch.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ada97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_content =[]\n",
    "for i in book_content_w_ch:\n",
    "    book_content.append(i.replace(i.split(' ')[0], ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b985405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(word):\n",
    "    word= word.lower()\n",
    "    word = word.replace('\\n','')\n",
    "    word  = re.sub(r'[^\\w\\s]', '', word)\n",
    "    word = re.sub('[0-9]', '', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d51469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    result = []\n",
    "    for line in data:\n",
    "        word = normalization(line)\n",
    "        word = word.lower().strip().split()\n",
    "        stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "        word = [lemmatizer.lemmatize(w) for w in word if not w in stopwords]\n",
    "        word = \" \".join(word)\n",
    "        result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15747f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_terms(listed):\n",
    "    normalized_text = []\n",
    "    collection_frequency = Counter()\n",
    "    document_frequency = Counter()\n",
    "    output_wordlist_dict ={}\n",
    "    terms_frequency = defaultdict(lambda: Counter([]))\n",
    "    \n",
    "    normalized_text = preprocess(listed)\n",
    "    \n",
    "    for i in range(len(normalized_text)):\n",
    "        tokenized_list= []\n",
    "        for j in normalized_text[i].split():\n",
    "            tokenized_list.append(j)\n",
    "        output_wordlist_dict[i] = Counter(tokenized_list)\n",
    "        collection_frequency.update(tokenized_list)\n",
    "        document_frequency.update(set(tokenized_list))\n",
    "        \n",
    "    for key, value in output_wordlist_dict.items():\n",
    "        for term, term_cnt in value.items():\n",
    "            terms_frequency[term][key] += term_cnt\n",
    "    \n",
    "    return normalized_text, collection_frequency, document_frequency, output_wordlist_dict, terms_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d0e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_list(listed):\n",
    "    sort_dict = {}\n",
    "    result_sort_dict = {}\n",
    "    offset_sum = 0\n",
    "    offset_i = 0\n",
    "    sort_dict = OrderedDict(sorted(listed.items()))\n",
    "    for i, value in enumerate(sort_dict.keys()):\n",
    "        offset_i = len(sort_dict[value]) * 2 \n",
    "        result_sort_dict[value] = len(sort_dict[value].values()),offset_sum\n",
    "        offset_sum = offset_sum + offset_i \n",
    "    return result_sort_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3451bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_corpus(dict_corpus,N_corpus):\n",
    "    idf_dict = {}\n",
    "    for key_i in dict_corpus.keys():\n",
    "        tf_i = dict_corpus.get(key_i)[0]\n",
    "        idf_i = math.log2(N_corpus/tf_i)\n",
    "        idf_dict[key_i] = idf_i\n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70d0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(post_list,idf_matrix):\n",
    "    weight_matrix =[]\n",
    "    for i, j in post_list.items():\n",
    "        idf ={}\n",
    "        for k in j:\n",
    "            if k not in idf_matrix:\n",
    "                idf_matrix[k] = 0\n",
    "            else:\n",
    "                idf[k] = idf_matrix[k]*j[k]\n",
    "        weight_matrix.append(idf)                       \n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64631465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_length(weight):\n",
    "    length_matrix = {}\n",
    "    for doc_i in range(len(weight)):\n",
    "        length_matrx = []\n",
    "        for i in weight[doc_i].values():\n",
    "            length_matrx.append(i)\n",
    "        sum_of_squares = sum(map(lambda k : k * k, length_matrx))\n",
    "        vlength = math.sqrt(sum_of_squares)\n",
    "        length_matrix[doc_i] = vlength\n",
    "    return length_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d9b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarities(doc_weight, query_weight, doc_length, query_length, query_term_freq):\n",
    "    N = len(doc_weight)\n",
    "    cos_score = []\n",
    "    for i in range(len(query_term_freq)):\n",
    "        cos_score.append([0]*N)\n",
    "        for j  in query_term_freq[i].keys():\n",
    "            query_tfidf = 0\n",
    "            if query_weight[i].get(j):\n",
    "                query_tfidf = query_weight[i].get(j)\n",
    "            for k in range(len(doc_weight)):\n",
    "                if(query_length[i] != 0) & (doc_length[k] != 0):\n",
    "                    if(doc_weight[k].get(j)):\n",
    "                        #Document Length * Query Length\n",
    "                        doc_query_length = doc_length[k] * query_length[i]\n",
    "                        # tf-idf weight of term in document * tf-idf weight of term in query\n",
    "                        doc_query_vector = doc_weight[k].get(j) * query_tfidf\n",
    "                        cos_score[i][k] += doc_query_vector / doc_query_length  \n",
    "    return cos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb90e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_set/book_norm_text.pickle', 'rb') as f:\n",
    "    book_normalized_text = pickle.load(f)\n",
    "\n",
    "with open('pickle_set/book_collec_freq.pickle', 'rb') as f:\n",
    "    book_collec_freq = pickle.load(f)\n",
    "\n",
    "with open('pickle_set/book_doc_freq.pickle', 'rb') as f:\n",
    "    book_doc_freq = pickle.load(f)\n",
    "    \n",
    "with open('pickle_set/book_term_freq.pickle', 'rb') as f:\n",
    "    book_term_freq = pickle.load(f)\n",
    "\n",
    "with open('pickle_set/book_dict_pos_output.pickle', 'rb') as f:\n",
    "    book_dict_pos_output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35551955",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_idf_matrix = idf_corpus(book_dict_pos_output,len(book_normalized_text))\n",
    "book_weight = tf_idf(book_term_freq, book_idf_matrix)\n",
    "book_length = vector_length(book_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "531c2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_content= ['Jesus saves us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10c02c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_normalized_text, q_collec_freq, q_doc_freq, q_term_freq, q_posting_list_output = calculate_terms(query_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb7676ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dict_pos_output = dictionary_list(q_posting_list_output)\n",
    "q_idf_matrix = idf_corpus(q_dict_pos_output,len(q_normalized_text))\n",
    "q_weight = tf_idf(q_term_freq, book_idf_matrix)\n",
    "q_length = vector_length(q_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aad58772",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_score_q = cosine_similarities(book_weight, q_weight, book_length, q_length, q_term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a121bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_list =[]\n",
    "for i in range(len(cos_score_q)):\n",
    "    ranked = []\n",
    "    for j in range(len(cos_score_q[i])):\n",
    "        ranked.append([j, cos_score_q[i][j]])\n",
    "    ranking_list.append(ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60b52ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ranking_list:\n",
    "    i.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bad67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "every_result =[]\n",
    "for i in ranking_list:\n",
    "    result =[]\n",
    "    for j in i[:10]:\n",
    "        result.append(book_content_w_ch[j[0]])\n",
    "    every_result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2798aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jesus saves us']\n"
     ]
    }
   ],
   "source": [
    "print(query_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f53ef7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Sm22:32 For who is God, save the LORD? and who is a rock, save our God?\n",
      "\n",
      "Psa18:31 For who is God save the LORD? or who is a rock save our God?\n",
      "\n",
      "Mat17:8 And when they had lifted up their eyes, they saw no man, save Jesus only.\n",
      "\n",
      "Psa55:16 As for me, I will call upon God; and the LORD shall save me.\n",
      "\n",
      "Mark9:8 And suddenly, when they had looked round about, they saw no man any more, save Jesus only with themselves.\n",
      "\n",
      "Mat1:21 And she shall bring forth a son, and thou shalt call his name JESUS: for he shall save his people from their sins.\n",
      "\n",
      "Hos1:7 But I will have mercy upon the house of Judah, and will save them by the LORD their God, and will not save them by bow, nor by sword, nor by battle, by horses, nor by horsemen.\n",
      "\n",
      "Psa69:1 Save me, O God; for the waters are come in unto my soul.\n",
      "\n",
      "1Cor2:2 For I determined not to know any thing among you, save Jesus Christ, and him crucified.\n",
      "\n",
      "Mat13:57 And they were offended in him. But Jesus said unto them, A prophet is not without honour, save in his own country, and in his own house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in every_result[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ba36767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.50607967376709 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcad57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
